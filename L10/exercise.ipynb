{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129dbd15",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb43db2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load vectors directly from the file\n",
    "# YOU HAVE TO CHANGE THE PATH\n",
    "model = KeyedVectors.load_word2vec_format('./wiki.en.vec.short50K', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f357f",
   "metadata": {},
   "source": [
    "Let's work on the geometric properties of word embeddings. What happens if we remove the content of *man* related to the word *king* and if we add the content of *woman*?\n",
    "\n",
    "If we want to do this, first we need to perform subtraction and addition over vectorial representations of the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83279c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.060511,  0.049607, -0.20885 ,  0.10349 ,  0.14276 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The vectorial representation of the word queen (first 5 numbers)\n",
    "model['queen'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655ebac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25962 ,  0.17535 , -0.12542 , -0.080696, -0.061302],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The vectorial representation of the word woman (first 5 numbers)\n",
    "model['woman'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c681e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.011586, -0.076437, -0.2499  ,  0.028163, -0.35323 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The vectorial representation of the word man (first 5 numbers)\n",
    "model['man'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8f1c9",
   "metadata": {},
   "source": [
    "Can you please calculate the resulting vector of removing the \"woman\" content and adding the \"man\" content? Then, you can save it in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "233eeff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "vec = model.get_vector('queen') - model.get_vector('woman') + model.get_vector('man')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac48bc04",
   "metadata": {},
   "source": [
    "Now you can use the function *model.similar_by_vector*, which does the same as the *model.most_similar* function, but instead of providing a word, we can provide a vector.\n",
    "\n",
    "Then, use the *model.similar_by_vector* function, and let's see what are the most similar words to that vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c214345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7898672223091125),\n",
       " ('king', 0.6429405808448792),\n",
       " ('majesty', 0.5372264385223389),\n",
       " ('monarch', 0.5126069784164429),\n",
       " ('crown', 0.4697607159614563),\n",
       " ('queens', 0.4569217562675476),\n",
       " ('whitehall', 0.45084935426712036),\n",
       " ('reign', 0.4498361051082611),\n",
       " ('coronation', 0.44729694724082947),\n",
       " ('royal', 0.43049025535583496)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "model.similar_by_vector(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e991b3a",
   "metadata": {},
   "source": [
    "Now, can you find more examples of that kind? Maybe not only with gender, but with cultures, geography, music, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c074085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langProc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
