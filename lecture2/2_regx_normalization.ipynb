{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333e54dd",
   "metadata": {},
   "source": [
    "## Regular expressions in python - module re\n",
    "## re.search(regexpr,word)    true if found\n",
    "## re.findall(regexpr, all)       returns list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51dde011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 8), match='s'>\n",
      "found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['s', 'd', 'd', 's', 's']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re  \n",
    "pattern= \"[ds]\"\n",
    "text='That was dreadful. \\n Yes,it was. \\n'\n",
    "print(re.search(pattern, text))\n",
    "if re.search(pattern, text):\n",
    "    print(\"found\")\n",
    "re.findall(pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad600ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(15, 28), match='0045-12345678'>\n",
      "Number found: 0045-12345678\n"
     ]
    }
   ],
   "source": [
    "# Define a regex pattern to match a phone number\n",
    "pattern = r\"\\d{4}-\\d{8}\"\n",
    "\n",
    "# Search for the pattern in the string\n",
    "result = re.search(pattern, \"My telefone is 0045-12345678\") #returns much object\n",
    "print(result)\n",
    "\n",
    "# Check if the pattern was found\n",
    "if result:\n",
    "    print(\"Number found:\", result.group())\n",
    "else:\n",
    "    print(\"No number found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b78978",
   "metadata": {},
   "source": [
    "## / is problematic use r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22842b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Line 75: Adler, of dubious and questionable memory.\n",
      "2: Line 102: keen desire to see Holmes again, and to know how he was employing his\n",
      "2: Line 134: been burned, had you lived a few centuries ago. It is true that I had a\n",
      "2: Line 197: means?”\n",
      "2: Line 430: been waylaid. There has been no result.”\n",
      "2: Line 675: mean to wear it on my watch chain in memory of the occasion.”\n",
      "2: Line 1846: seen, and yet from his words it was evident that he saw clearly not\n",
      "2: Line 2853: been talking, and he rose from his chair now with a cold sneer upon his\n",
      "2: Line 3178: being somewhat cold and forbidding in his manners, but he had, as far\n",
      "2: Line 3335: been a little quick in forming his conclusions,” he said.\n",
      "2: Line 3608: been here before they came like a herd of buffalo and wallowed all over\n",
      "2: Line 3864: been a long time in the acting, but will not take me long to tell.\n",
      "1: Line 4374: Again Holmes raved in the air.\n",
      "1: Line 4406: Augustine.\n",
      "2: Line 4442: meanwhile, for I do not think that there can be a doubt that you are\n",
      "2: Line 5420: been used. If it had been written straight off, and then blotted, none\n",
      "2: Line 5423: mean that he was not familiar with it. It is, of course, a trifle, but\n",
      "2: Line 5626: being concerned in the disappearance of Mr. Neville St. Clair, of Lee.”\n",
      "2: Line 5717: been committed, and that, therefore, I am illegally detained.”\n",
      "2: Line 5813: being identified as Mr. Neville St. Clair, I was arrested as his\n",
      "2: Line 6128: been referred to the Assizes. I have some account of the matter here, I\n",
      "2: Line 6629: been concerned in some such matter before, and that suspicion would\n",
      "2: Line 6670: been serving his time in Pentonville. One day he had met me, and fell\n",
      "2: Line 6960: been intensified by his long residence in the tropics. A series of\n",
      "2: Line 7217: leaning back in his chair.\n",
      "2: Line 7527: keenest interest.\n",
      "2: Line 7752: seen it in the daytime. Then creeping up to me and making a trumpet of\n",
      "2: Line 8018: been. It had been hacked or torn right out from the roots.\n",
      "2: Line 8024: been senseless for a long time. When I came to I found that it was\n",
      "2: Line 8148: been recommended to me, Mr. Hatherley, as being a man who is not only\n",
      "2: Line 8231: be no chance of a train back. I should be compelled to stop the night.’\n",
      "2: Line 8304: been intrusted to me. On the one hand, of course, I was glad, for the\n",
      "2: Line 8808: been already referred to.\n",
      "2: Line 8825: being excellent company for the remainder of your existence.”\n",
      "2: Line 9081: been to command and to be obeyed. His manner was brisk, and yet his\n",
      "2: Line 9217: seen that her temper was just a little sharp. The incident however, was\n",
      "2: Line 9291: been on a friendly footing for some years—I may say on a _very_\n",
      "2: Line 10879: keenest pleasure is to be derived. It is pleasant to me to observe,\n",
      "2: Line 10935: been novel and of interest.”\n",
      "2: Line 11434: been with them he has been quite drunk, and yet Mr. Rucastle seemed to\n",
      "2: Line 11542: keen as mustard. Toller lets him loose every night, and God help the\n",
      "2: Line 11672: keenly on my guard against him.\n",
      "1: Line 11797: A loud thudding noise came from somewhere downstairs. “That is Mrs.\n",
      "2: Line 11867: keen white teeth still meeting in the great creases of his neck. With\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def print_res(regx, st):\n",
    "    if re.search(regx, st):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Open the \"sherlock.txt\" file with UTF-8 encoding\n",
    "with open(\"sherlock.txt\", encoding=\"utf-8\") as f:\n",
    "    for line_number, line in enumerate(f, start=1):\n",
    "        if print_res(r'^A.*\\.$', line):\n",
    "            print(f\"1: Line {line_number}: {line.strip()}\")\n",
    "            \n",
    "        elif print_res(r'^.{1}e.n', line):\n",
    "            print(f\"2: Line {line_number}: {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055411e",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "test what happens when you run the above code if you remove the r before the pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1667067",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Write a function \"print_res\" that takes a regular expression and a string as parameters, and returns the string if it contains the given regular expression.\n",
    "read the file sherlock.txt (encoding=\"utf8\" when you open it) then call your function so that the following is done:\n",
    "\n",
    "1: all lines that start with \"A\" (capital a) and end with a fullstop are printed. \n",
    "2: all lines that start with \"H\" and contain 70 characters are printed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28317aaf",
   "metadata": {},
   "source": [
    "## Exercise  2a\n",
    "Define a function \"print_lines\" that takes a file and a regular expression as parameters and\n",
    "prints all lines that contain the pattern preceding them with their line number. Run \"print_lines with the file sherlock.txt and a regular expression that finds lines containing an \"e\" as the second character and \"n\" as the third one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d6981",
   "metadata": {},
   "source": [
    "## From the nltk book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e74c437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oared\n",
      "oarweed\n",
      "oathed\n",
      "oatseed\n",
      "obcompressed\n",
      "obliged\n",
      "oblongated\n",
      "obtected\n",
      "obvoluted\n",
      "oceaned\n",
      "ocellated\n",
      "ocreated\n",
      "octahydrated\n",
      "octofoiled\n",
      "octoped\n",
      "octoradiated\n",
      "oculated\n",
      "odored\n",
      "oersted\n",
      "offended\n",
      "offhanded\n",
      "ogeed\n",
      "ogived\n",
      "oiled\n",
      "oilseed\n",
      "oilskinned\n",
      "oldfangled\n",
      "oldhearted\n",
      "olived\n",
      "omened\n",
      "onehearted\n",
      "onesigned\n",
      "onflemed\n",
      "onionized\n",
      "opaled\n",
      "openhanded\n",
      "openhearted\n",
      "openmouthed\n",
      "opercled\n",
      "operculated\n",
      "opinionated\n",
      "opinioned\n",
      "opposed\n",
      "oppressed\n",
      "orbed\n",
      "orbiculated\n",
      "ordered\n",
      "oreweed\n",
      "organized\n",
      "origanized\n",
      "orphreyed\n",
      "orthosubstituted\n",
      "osiered\n",
      "ossified\n",
      "outbleed\n",
      "outbowed\n",
      "outbred\n",
      "outbreed\n",
      "outdated\n",
      "outed\n",
      "outeyed\n",
      "outlined\n",
      "outlipped\n",
      "outmoded\n",
      "outplayed\n",
      "outriggered\n",
      "outsided\n",
      "outsized\n",
      "outspeed\n",
      "outturned\n",
      "outweed\n",
      "ovated\n",
      "overalled\n",
      "overambitioned\n",
      "overappareled\n",
      "overapprehended\n",
      "overattached\n",
      "overbanded\n",
      "overbanked\n",
      "overbepatched\n",
      "overblessed\n",
      "overbowed\n",
      "overbrained\n",
      "overbred\n",
      "overbreed\n",
      "overburned\n",
      "overcoached\n",
      "overcoated\n",
      "overconcerned\n",
      "overcontented\n",
      "overcorned\n",
      "overcreed\n",
      "overcrowded\n",
      "overcultured\n",
      "overcured\n",
      "overdazed\n",
      "overdelighted\n",
      "overdetermined\n",
      "overdevoted\n",
      "overdignified\n",
      "overdistempered\n",
      "overdrifted\n",
      "overdrowsed\n",
      "overdubbed\n",
      "overdunged\n",
      "overeducated\n",
      "overempired\n",
      "overexerted\n",
      "overeyebrowed\n",
      "overfagged\n",
      "overfamed\n",
      "overfeatured\n",
      "overfed\n",
      "overfeed\n",
      "overfinished\n",
      "overfleshed\n",
      "overforged\n",
      "overformed\n",
      "overfranchised\n",
      "overfrighted\n",
      "overfruited\n",
      "overgalled\n",
      "overgifted\n",
      "overgilted\n",
      "overgirded\n",
      "overgreed\n",
      "overhanded\n",
      "overhatted\n",
      "overinclined\n",
      "overinterested\n",
      "overinventoried\n",
      "overjaded\n",
      "overjawed\n",
      "overlanguaged\n",
      "overlearned\n",
      "overleisured\n",
      "overlettered\n",
      "overlighted\n",
      "overlightheaded\n",
      "overlinked\n",
      "overlisted\n",
      "overmelodied\n",
      "overmettled\n",
      "overnoveled\n",
      "overofficered\n",
      "overornamented\n",
      "overpained\n",
      "overparted\n",
      "overpitched\n",
      "overplaced\n",
      "overpointed\n",
      "overpronounced\n",
      "overproportionated\n",
      "overproportioned\n",
      "overrefined\n",
      "overreserved\n",
      "overrigged\n",
      "overrooted\n",
      "oversanded\n",
      "oversated\n",
      "overscented\n",
      "overscutched\n",
      "overseasoned\n",
      "overseated\n",
      "overseed\n",
      "oversettled\n",
      "overshowered\n",
      "oversized\n",
      "oversophisticated\n",
      "oversorrowed\n",
      "overspangled\n",
      "oversparred\n",
      "overspeed\n",
      "overstalled\n",
      "overstowed\n",
      "overstudied\n",
      "oversweated\n",
      "overtapped\n",
      "overtimbered\n",
      "overtinseled\n",
      "overtongued\n",
      "overtrailed\n",
      "overunionized\n",
      "overwasted\n",
      "overweaponed\n",
      "overwhipped\n",
      "overwiped\n",
      "overwithered\n",
      "overwooded\n",
      "overwrested\n",
      "oviculated\n",
      "oxidulated\n",
      "oystered\n",
      "oysterseed\n",
      "ozoned\n"
     ]
    }
   ],
   "source": [
    "import nltk, re\n",
    "wordlist = [w for w in nltk.corpus.words.words('en')]\n",
    "len(wordlist)\n",
    "for word in wordlist:\n",
    "    if re.search(r'^(o|O).*ed$', word):\n",
    "        print(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5bc2d",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "Find all words in wordlist that start with \"o\" or \"O\" and end with \"ed\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5486b8",
   "metadata": {},
   "source": [
    "## From NLTK book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff4da7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2009, 12, 11]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "[int(n) for n in re.findall('[0-9]{2,4}','2009-12-11')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80239e09",
   "metadata": {},
   "source": [
    "# Basic Text Processing and Text Normalization\n",
    "1. Tokenization: segmenting text in tokens (words, numbers, punctuation)\n",
    "2. Text Normalization: normalising various word formats\n",
    "3. Segmenting sentences \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56feba",
   "metadata": {},
   "source": [
    "# Tokenization based on spaces\n",
    "The simplest way to tokenize in python is text.split()\n",
    "It works for  languages that \n",
    "use space characters between words, such as Arabic, Cyrillic, Greek, Latin, etc., based writing system\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1b294",
   "metadata": {},
   "source": [
    "## Search tokenized text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "from nltk.corpus import gutenberg,nps_chat\n",
    "sense=nltk.Text(gutenberg.words(\"austen-sense.txt\"))\n",
    "sense.findall(\"<a> (<.*>) <woman>\")     \n",
    "sense.findall(\"<a> (<.*>) <man>\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10231259",
   "metadata": {},
   "source": [
    "## Exercise 4 : \n",
    "1. Find all occurrences of 'who' following 'man' in austen-sense.txt \n",
    "2. Find all occurrences of as x as y  in austen-sense.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601c320",
   "metadata": {},
   "source": [
    "# Tokenization: distinguishing words\n",
    "in Python you can tokenize a test with split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"\"\"The orchestra played a new song. Mr. Brown didn't like it, even if he had payed 2,000$ for it. He said: 'That was a pity!'\"\"\" \n",
    "mytext.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e9f83",
   "metadata": {},
   "source": [
    "## Do you notice any problem?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ad652",
   "metadata": {},
   "source": [
    "## Exercise 5:\n",
    "1. Write a tokenizer for English using regular expressions.\n",
    "2. test it on mytext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b3d56",
   "metadata": {},
   "source": [
    "## Are there more problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d4f52",
   "metadata": {},
   "source": [
    "## NLTK contains tokenizers for most types of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"\"\"The orchestra played a new song. Mr. Brown didn't like it, even if he had payed 2,000 $ for it. He said: 'That was a pity'\"\"\" \n",
    "word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384a190",
   "metadata": {},
   "source": [
    "# Many languages, e.g. Chinese and Japanese do not use spaces to separate words.\n",
    "### Example from LP3: \n",
    "Chinese  姚明进入总决赛  “Yao Ming reaches the finals”\n",
    "姚明进入总决赛  “Yao Ming reaches the finals”\n",
    "\n",
    "3 words?\n",
    "姚明        进入      总决赛 \n",
    "YaoMing  reaches  finals \n",
    "\n",
    "5 words?\n",
    "姚       明      进入         总          决赛 \n",
    "Yao    Ming    reaches    overall    finals \n",
    "\n",
    "7 characters? (don't use words at all):\n",
    "姚   明        进      入       总         决         赛 \n",
    "Yao Ming enter enter overall decision game\n",
    "\n",
    "In Chinese it's common to just treat each character (zi) as a token and the segmentation step is very simple. In other languages, more complex word segmentation is required. The standard algorithms are neural sequence models trained by supervised machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67606f12",
   "metadata": {},
   "source": [
    "# Word Normalization\n",
    "## a) Words or tokens are put in standard format, e.g. U.S.A. or USA, large, LARGE, has have.\n",
    "## Case folding: Changes characters to upper or lower case.\n",
    "Which information is then missing?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfbfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "mytext.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d809112",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(mytext.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac1085",
   "metadata": {},
   "source": [
    "# Finding word stems \n",
    "In English e.g. removing suffixes.\n",
    "\n",
    "## Exercise 6:\n",
    "In NLTK book there is an easy implementation of a stemming function.\n",
    "Test it on the sentence: \" Hi guys! Try the stemming of this text relating to women and men, who are sitting on the banks in this big garden, where there are many geese and ducks .\"\n",
    "Hint: first tokenize and case normalize,  then run the stem function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    suffixes=['ing','ly','ed','ious','ies','ive','es','s','ment']\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a61926",
   "metadata": {},
   "source": [
    "## Exercise 7:\n",
    "Run the nltk.PorterStemmer on raw. Compare the results with those obtained with the function \"stem and discuss the differences in groups of 2 or 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55508596",
   "metadata": {},
   "source": [
    "# Sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer=nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "with open(sherlock,'r',encoding=\"utf-8\") as f:\n",
    "    txt=f.read()\n",
    "    sents=sent_tokenizer.tokenize(txt)\n",
    "    print(sents[100:130])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01e307",
   "metadata": {},
   "source": [
    "## Exercise - extra\n",
    "Make a function that reads a text file and write in a file \"newfile.txt\" the same file, but with all empy lines removed.\n",
    "Test the function with \"sherlock.txt\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
